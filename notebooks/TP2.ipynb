{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 2: Enunciado "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El segundo TP es una competencia de Machine Learning en donde cada grupo debe intentar determinar, para cada tweet brindado, si el mismo esta basado en un hecho real o no.\n",
    "\n",
    "La competencia se desarrolla en la plataforma de Kaggle  https://www.kaggle.com/c/nlp-getting-started.  \n",
    "\n",
    "El dataset consta de una serie de tweets, para los cuales se informa:\n",
    "\n",
    "<br/>\n",
    "\n",
    "* id - identificador unico para cada  tweet\n",
    "* text - el texto del tweet\n",
    "* location - ubicación desde donde fue enviado (podría no estar)\n",
    "* keyword - un keyword para el tweet  (podría faltar)\n",
    "* target - en train.csv, indica si se trata de un desastre real  (1) o no (0)\n",
    " \n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "Los submits con el resultado deben tener el formato:\n",
    "\n",
    "Id: Un id numérico para identificar el tweet\n",
    "target: 1 / 0 según se crea que el tweet se trata sobre un desastre real, o no.\n",
    "\n",
    "Los grupos deberán probar distintos algoritmos de Machine Learning para intentar predecir si el tweet está basado en hechos reales o no. A medida que los grupos realicen pruebas deben realizar el correspondiente submit en Kaggle para evaluar el resultado de los mismos.\n",
    "\n",
    "Al finalizar la competencia el grupo que mejor resultado tenga obtendrá 10 puntos para cada uno de sus integrantes que podrán ser usados en el examen por promoción o segundo recuperatorio.\n",
    "\n",
    "Requisitos para la entrega del TP2:\n",
    "\n",
    "- El TP debe programarse en Python o R.\n",
    "- Debe entregarse un pdf con el informe de algoritmos probados, algoritmo final utilizado, transformaciones realizadas a los datos, feature engineering, etc. \n",
    "- El informe debe incluir también un link a github con el informe presentado en pdf, y todo el código.\n",
    "- El grupo debe presentar el TP en una computadora en la fecha indicada por la cátedra, el TP debe correr en un lapso de tiempo razonable (inferior a 1 hora) y generar un submission válido que iguale el mejor resultado obtenido por el grupo en Kaggle. (mas detalles a definir)\n",
    "\n",
    "El TP2 se va a evaluar en función del siguiente criterio:\n",
    "\n",
    "- Cantidad de trabajo (esfuerzo) del grupo: ¿Probaron muchos algoritmos? ¿Hicieron un buen trabajo de pre-procesamiento de los datos y feature engineering?\n",
    "- Resultado obtenido en Kaggle (obviamente cuanto mejor resultado mejor nota)\n",
    "- Presentación final del informe, calidad de la redacción, uso de información obtenida en el TP1, conclusiones presentadas.\n",
    "- Performance de la solución final.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocesado\n",
    "#### Introducción \n",
    "Se levantan los datos como en el TP1. Sin EDA, solo el preprocesado del texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Instalación de librerias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install stopwords\n",
    "!pip install gensim\n",
    "\n",
    "!pip install sklearn\n",
    "!pip install xgboost==0.7.post4\n",
    "\n",
    "!pip3 install tensorflow\n",
    "!pip3 install tensorflow_hub\n",
    "!pip3 install tqdm>=4.46.0\n",
    "\n",
    "!pip3 install keras\n",
    "!pip3 install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, Perceptron\n",
    "from sklearn.metrics import f1_score,roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from time import process_time\n",
    "\n",
    "import tensorflow_hub as hub \n",
    "import tensorflow as tf \n",
    "\n",
    "from tqdm.notebook import tqdm \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Obtención de datos\n",
    "Lectura de datos de entrenamiento y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train = pd.read_csv('../data/train.csv', encoding='utf-8')\n",
    "tweets_test = pd.read_csv('../data/test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Limpieza de datos.\n",
    "#### Introducción\n",
    "Antes de empezar, hay que normalizar el texto ya que luego de la tokenización serán convertidos en vectores dentro de una matriz, las técnicas a utilizar:\n",
    "* **Uppercase/lowercase**: Paso todo a lower/upper case, ya que una misma palabra tiene una representación distinta si se hay un cambio de mayúscula minúscula.\n",
    "* **Limpieza de texto**: Signos de puntuación, valores numéricos, links, carácteres especiales, etc.\n",
    "* **Tokenizacion**: Es el proceso de convertir el texto en una lista de tokens,\n",
    "* **Stopwords**: Elimino palabras comunes que no aportan información\n",
    "* **Stemming**: Elimino los sufijos de palabras que puedan tener el mismo significado (o función dentro del texto)\n",
    "* **Lemmatization**: Unifico palabras que signifiquen lo mismo en base a su definición del diccionario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializo dataset para probar las funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copia de datasets para trabajar el pre-procesado de texto\n",
    "train_df1 = tweets_train.copy()\n",
    "test_df1  = tweets_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Uppercase + Limpieza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para eliminar emojis, viene del tp1\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)\n",
    "\n",
    "def remove_emojis_non_ascii(text):    \n",
    "    #replace consecutive non-ASCII characters with a space\n",
    "    result = re.sub(r'[^\\x00-\\x7F]+',' ', text)\n",
    "    #remove emojis from tweet\n",
    "    result = emoji_pattern.sub(r'', result)    \n",
    "    return result\n",
    "\n",
    "\n",
    "#Funcion para limpieza del texto (todo a LOWERCASE)\n",
    "def text_clean(text):\n",
    "    text = text.lower()\n",
    "    text = remove_emojis_non_ascii(text)\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplico la funcion a la copia de los Dataset de entrenamiento y test\n",
    "train_df1['text'] = train_df1['text'].progress_apply(lambda x: text_clean(x))\n",
    "test_df1['text'] = test_df1['text'].progress_apply(lambda x: text_clean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Tokenización\n",
    "_Probar los distintos que ofrece la librería nltk_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para tokenizar utilizo el RegEx tokenizer de nltk\n",
    "#tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "#Para tokenizar utilizo WhitespaceTokenizer\n",
    "#tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "\n",
    "#Para tokenizar utilizo WordPunctTokenizer\n",
    "#tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "\n",
    "#Para tokenizar utilizo TreebankWordTokenizer\n",
    "self_tokenizer = nltk.tokenize.TreebankWordTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['text'] = train_df1['text'].progress_apply(lambda x: self_tokenizer.tokenize(x))\n",
    "test_df1['text'] = test_df1['text'].progress_apply(lambda x: self_tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3 Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para eliminar Stopwords\n",
    "def text_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['text'] = train_df1['text'].progress_apply(lambda x : text_stopwords(x))\n",
    "test_df1['text'] = test_df1['text'].progress_apply(lambda x : text_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.4 Stemming + Lemmatizing\n",
    "Probar si aportan algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para Stemming y Lemmatizing\n",
    "def text_stemming(text):\n",
    "    tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    text_stemmed = \" \".join(stemmer.stem(token) for token in tokens)\n",
    "    return text_stemmed\n",
    "\n",
    "def text_lemmatizing(text):\n",
    "    tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    lemmatizer=nltk.stem.WordNetLemmatizer()\n",
    "    text_lemmatized = \" \".join(lemmatizer.lemmatize(token) for token in tokens)\n",
    "    return text_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combino el texto para luego de haberlo procesado\n",
    "def text_combine(text):\n",
    "    comb_text = ' '.join(text)\n",
    "    return comb_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['text'] = train_df1['text'].apply(lambda x : text_combine(x))\n",
    "test_df1['text'] = test_df1['text'].apply(lambda x : text_combine(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1.head() ##Datos Antes del lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1['text'] = test_df1['text'].progress_apply(lambda x : text_lemmatizing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1.head() ##Datos luego del lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.5 Pre-procesado de texto\n",
    "Devuelve texto, agregar una para devolver tambien solo TOKENS, ya que es lo que se va a utilizar para entrenar al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_text(text): \n",
    "    cleaned_txt = text_clean(text)\n",
    "    lemma_text = text_lemmatizing(cleaned_txt)\n",
    "    tokenized_text = self_tokenizer.tokenize(lemma_text)    \n",
    "    remove_stopwords = text_stopwords(tokenized_text)\n",
    "    combined_text = text_combine(remove_stopwords)\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df1['text'] = test_df1['text'].progress_apply(lambda x : pre_process_text(x))\n",
    "test_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Vectorización del texto\n",
    "Para entrenar el modelo necesitamos convertir el texto a una matriz de vectores para que pueda interpretarlo, \n",
    "para lograrlo existen distintas técnicas.\n",
    "\n",
    "\n",
    "* Bag of Words\n",
    "* TF-IDF\n",
    "* N-Gramas\n",
    "* Feature Hashing\n",
    "* Red convolucional 1-D\n",
    "\n",
    "\n",
    "Cada una de estas alternativas esta directamente relacionada con la transformación del texto (Tokenizacion, limpieza, lemming, stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Preparacion de datasets - funciones\n",
    "Preparo datasets de train y test aplicando el preprocesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2=tweets_train.copy()\n",
    "train_df2['text'] = train_df2['text'].progress_apply(lambda x : pre_process_text(x))\n",
    "\n",
    "test_df2=tweets_test.copy()\n",
    "test_df2['text'] = test_df2['text'].progress_apply(lambda x : pre_process_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Es necesario el parseo a String, porque ciertos keywords se convierten a numerico\n",
    "train_df2['keyword'] = train_df2['keyword'].progress_apply(lambda x : pre_process_text(str(x)))\n",
    "\n",
    "test_df2=tweets_test.copy()\n",
    "test_df2['keyword'] = test_df2['keyword'].progress_apply(lambda x : pre_process_text(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defino una función para visualizar las distintas vectorizaciones. La idea es poder visualizar la distancia que existe entre los tokens de cada tweet (verdaderos/falsos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Funcion interna\n",
    "def plot_LSA(test_data, test_labels):\n",
    "        lsa = TruncatedSVD(n_components=2)\n",
    "        lsa.fit(test_data)\n",
    "        lsa_scores = lsa.transform(test_data)\n",
    "        color_mapper = {label:idx for idx,label in enumerate(set(test_labels))}\n",
    "        color_column = [color_mapper[label] for label in test_labels]\n",
    "        colors = ['orange','blue']        \n",
    "        plt.scatter(lsa_scores[:,0], lsa_scores[:,1], s=8, alpha=.8, c=test_labels, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "        orange_patch = mpatches.Patch(color='orange', label='Falso')\n",
    "        blue_patch = mpatches.Patch(color='blue', label='Verdadero')\n",
    "        plt.legend(handles=[orange_patch, blue_patch], prop={'size': 30})\n",
    "\n",
    "\n",
    "list_text = train_df2[\"text\"].tolist()\n",
    "list_keyword = train_df2[\"keyword\"].tolist()\n",
    "list_labels = train_df2[\"target\"].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_text, list_labels, test_size=0.2, \n",
    "                                                                            random_state=32)            \n",
    "\n",
    "X_train_k, X_test_k, y_train_k, y_test_k = train_test_split(list_keyword, list_labels, test_size=0.2, \n",
    "                                                                            random_state=32)    \n",
    "##ultima funcion\n",
    "##train_x es el array de la columna text, vectorizado\n",
    "def Graph_vectorization(train_x,train_y,model_name):\n",
    "    fig = plt.figure(figsize=(16, 16))          \n",
    "    plot_LSA(train_x, train_y)\n",
    "    fig.suptitle(model_name)    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embbeding\n",
    "\n",
    "## w2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "#glove-twitter-100 1193514 387 MB  Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\n",
    "#glove-twitter-200 1193514 758 MB  Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\n",
    "#glove-twitter-25  1193514 104 MB  Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\n",
    "#glove-twitter-50  1193514 199 MB  Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\n",
    "model = api.load(\"glove-twitter-200\")  # download the model and return as object ready for use\n",
    "\n",
    "#word2vec = gensim.models.KeyedVectors.load_word2vec_format(path_for_word2vec, binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec, dimentions):\n",
    "        self.word2vec = word2vec\n",
    "        # dimension del vector\n",
    "        self.dim = dimentions\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # tranformación: se busca la palabra en el modelo de w2vec, si no existe se llena con ceros el vector\n",
    "        # se calcula el promedio para el vector final\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec, dimentions):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = dimentions\n",
    "\n",
    "    def fit(self, X):\n",
    "        # TODO ver si estos parametros estan OK\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x,min_df=2, max_df=0.5, ngram_range=(2, 3))\n",
    "        tfidf.fit(X)\n",
    "        # Se calcula el \"peso\" de cada palabra: \n",
    "        # usando el mayor valor de tf-idf \n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w] for w in words if w in self.word2vec]\n",
    "                        or [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# armamos el diccionario de w2vec\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanEmbedding = MeanEmbeddingVectorizer(w2v, model.vector_size)\n",
    "train_w2vec = meanEmbedding.transform(train_df2.text)\n",
    "test_w2vec = meanEmbedding.transform(test_df2.text)\n",
    "\n",
    "graph_w2vec_x = meanEmbedding.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w2vec_k =  meanEmbedding.transform(train_df2.keyword)\n",
    "test_w2vec_k = meanEmbedding.transform(test_df2.keyword)\n",
    "\n",
    "graph_w2vec_x_k = meanEmbedding.transform(X_train_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfEmbedding = TfidfEmbeddingVectorizer(w2v, model.vector_size)\n",
    "train_w2vecTfid = tfidfEmbedding.fit(train_df2.text).transform(train_df2.text)\n",
    "test_w2vecTfid = tfidfEmbedding.transform(test_df2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico vectorizacion\n",
    "Graph_vectorization(graph_w2vec_x,y_train,\"MeanEmbeding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico vectorizacion\n",
    "Graph_vectorization(graph_w2vec_x_k,y_train_k,\"MeanEmbeding (KEYWORD)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeding: Universal Sentence Encoder (tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_use = 'https://tfhub.dev/google/universal-sentence-encoder-large/5'\n",
    "embed = hub.load(large_use)\n",
    "\n",
    "def transfrom(text_train, text_test):\n",
    "\n",
    "\n",
    "    vector_train = [tf.reshape(embed([line]), [-1]).numpy() for line in tqdm(text_train)]\n",
    "    vector_test = [tf.reshape(embed([line]), [-1]).numpy() for line in tqdm(text_test)]\n",
    "\n",
    "    return vector_train, vector_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paso el texto a vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_use_tf, test_use_tf = transfrom(train_df2.text, test_df2.text)\n",
    "train_use_tf_k, test_use_tf_k = transfrom(train_df2.keyword, test_df2.keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico vectorizacion\n",
    "graph_useftx, _dummy = transfrom(X_train, X_train)\n",
    "Graph_vectorization(graph_useftx,y_train,\"USE tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico vectorizacion (KEYWORDS)\n",
    "graph_useftx_k, _dummy = transfrom(X_train_k, X_train_k)\n",
    "Graph_vectorization(graph_useftx_k,y_train_k,\"USE tensorflow + (KEYWORDS)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Bag of Words\n",
    "Se crea un diccionario de palabras conocidas, luego de eso se representa el texto en un vector donde cada posición indica la existencia (o no) de las palabras.\n",
    "\n",
    "#### CountVectorize\n",
    "\n",
    "CountVectorize convierte una coleccion de documentos a una matriz de tokens contabilizados. Esta funcion incluye varios metodos para preprocedo/tokenizacion/stopwords, por lo que se podría modificar desde la siguiente línea. Sin embargo, como ya se hizo el pre-procesado del texto solo voy a usar la función sin ningun feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizacion con countVectorize\n",
    "count_vectorizer = CountVectorizer()\n",
    "train_cv = count_vectorizer.fit_transform(train_df2['text'])\n",
    "test_cv = count_vectorizer.transform(test_df2[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico vectorizacion\n",
    "graph_cv =  count_vectorizer.fit_transform(X_train)\n",
    "Graph_vectorization(graph_cv,y_train,\"CountVectorize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico vectorizacion\n",
    "graph_cv_k =  count_vectorizer.fit_transform(X_train_k)\n",
    "Graph_vectorization(graph_cv_k,y_train_k,\"CountVectorize (KEYWORD)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 TF-IDF\n",
    "Tf-idf (Term frequency – Inverse document frequency), frecuencia de término – frecuencia inversa de documento (o sea, la frecuencia de ocurrencia del término en la colección de documentos), es una medida numérica que expresa cuán relevante es una palabra para un documento en una colección. \n",
    "Es una mejora de Bag of Words ya que contabiliza y pondera las palabras en base a su frecuencia de aparición en el documento, por ejemplo la palabra \"the\" puede tener muchas apariciones en el texto, por lo que se podria dar una importancia menor.\n",
    "\n",
    "#### **Calculo TD-IDF**\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Term Frequency(TF)**: Es la ponderación de la palabra dentro del documento\n",
    "\n",
    "$ {\\displaystyle tf} = \\frac{fdt}{nT}$\n",
    "<br/>\n",
    "Donde:\n",
    "* $ fdt $: Frecuencia de aparición del término t en el documento\n",
    "* $ nT $: Número de términos en el documento\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Inverse Document Frequency(IDF)**: Es el valor de que tan \"rara\" es la palabra a través de todos los documentos\n",
    "\n",
    "$ {\\displaystyle idf} = 1+\\log(\\frac{N}{n}) $ \n",
    "<br/>\n",
    "Donde:\n",
    "* $ N $: numero de documentos\n",
    "* $ n $: numero de documentos con aparición del termino t\n",
    "\n",
    "<br/>\n",
    "\n",
    "**TF-IDF**: La ponderación del termino por tf-idf está dada por\n",
    "\n",
    "$ {\\displaystyle tfidf}(w,d,D) = {\\displaystyle tf}(w,d) \\times {\\displaystyle idf}(w,D) $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizacion utilizando TF-IDF (UNI Y BI-GRAMAS)\n",
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
    "train_tf = tfidf.fit_transform(train_df2['text'])\n",
    "test_tf = tfidf.transform(test_df2[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parámetros TfidfVectorizer**\n",
    "\n",
    "* _mindf_ = cantidad o porcentaje minimo de aparición del token en todos los documentos. En este caso se descartan todas las que tengan menos de 2 apariciones\n",
    "\n",
    "* _maxdf_ = cantidad o porcentaje maximo de aparición del token. En este caso se descartan todos los token que tengan una frecuencia de aparición mayor al 50%\n",
    "\n",
    "* _ngramrange_ = Rango de ngramas a utilizar para generar los tokens. En este caso se usan desde 1 a 2 gramas (uni y bi-grama)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico vectorizacion\n",
    "graph_tf =  tfidf.fit_transform(X_train)\n",
    "Graph_vectorization(graph_tf,y_train,\"TF-IDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico vectorizacion\n",
    "graph_tf =  tfidf.fit_transform(X_train_k)\n",
    "Graph_vectorization(graph_tf,y_train_k,\"TF-IDF (KEYWORD)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 N-Gramas\n",
    "Agrupo las palabras en grupos de 1,2,3,n palabras, para agregarles un contexto.\n",
    "\n",
    "Esto se puede lograr utilizando countVectorize para analizar la frecuencia de aparición de n-gramas o combinarlo con tf-idf para considerar la ponderación del término en base a sus apariciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupo por bi-gramas y tri-gramas con CountVectorizer\n",
    "ngram_cv = CountVectorizer(ngram_range=(2,3))\n",
    "train_ng_cv = ngram_cv.fit_transform(train_df2['text'])\n",
    "test_ng_cv = ngram_cv.transform(test_df2[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupo por bi-gramas y tri-gramas con TF-IDF\n",
    "ngram_tf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(2, 3))\n",
    "train_ng_tf = ngram_tf.fit_transform(train_df2['text'])\n",
    "test_ng_tf = ngram_tf.transform(test_df2[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico vectorizacion\n",
    "graph_cv_ngs =  ngram_cv.fit_transform(X_train)\n",
    "Graph_vectorization(graph_cv_ngs,y_train,\"Count vectorizer + (2-3)Grama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico vectorizacion\n",
    "graph_tf_ng =  ngram_tf.fit_transform(X_train)\n",
    "Graph_vectorization(graph_tf_ng,y_train,\"TF-IDF + (2-3)Grama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Feature Hashing\n",
    "Pendiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorizacion usando Feature hashing\n",
    "hv = HashingVectorizer()\n",
    "train_fh = hv.fit_transform(train_df2[\"text\"])\n",
    "test_fh = hv.transform(test_df2[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico vectorizacion\n",
    "graph_fh =  hv.fit_transform(X_train)\n",
    "Graph_vectorization(graph_fh,y_train,\"Feature Hashing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Entrenamiento del modelo \n",
    "Para el entrenamiento pruebo algunos algoritmos _(en verde los probados, en rojo los descartados por ineficientes)_\n",
    "* <font color='green'>Logistic Regression </font>\n",
    "* <font color='green'>Decision tree</font>\n",
    "* <font color='green'>KNN</font>\n",
    "* <font color='green'>Gradient Boosting Clasifier</font>\n",
    "* <font color='green'>Random Forest</font>\n",
    "* <font color='green'>RidgeClassifier</font>\n",
    "* <font color='green'>MNB (MultinomialNB)</font>\n",
    "* <font color='green'>Perceptron</font>\n",
    "* <font color='green'>xgBoost</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrego feature de sentimiento\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "train_df2['sentiment_score'] = train_df2.text.apply(lambda x: sid.polarity_scores(x)['compound'])\n",
    "test_df2['sentiment_score'] = test_df2.text.apply(lambda x: sid.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2['sentiment_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1  Validation curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos la curva de aprendizaje para evaluar cuales son los mejores ratios a tomar para aprendizaje/test de cada modelo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training score and the validation score are both low, the estimator will be underfitting. If the training score is high and the validation score is low, the estimator is overfitting and otherwise it is working very well. A low training score and a high validation score is usually not possible. All three cases can be found in the plot below where we vary the parameter of an SVM on the digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores, valid_scores = validation_curve(GradientBoostingClassifier(learning_rate=0.0055, max_depth=2, max_features=27,\n",
    "                           min_samples_leaf=23, n_estimators=4850,random_state=2020)\n",
    "                                              , train_use_tf2_s, tweets_train.target, \"ccp_alpha\",\n",
    "                                               np.logspace(-4, 1, 30),\n",
    "                                               cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoostingClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(-7, 3, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(valid_scores, axis=1)\n",
    "test_scores_std = np.std(valid_scores, axis=1)\n",
    "\n",
    "param_range = np.logspace(-4, -1, 30)\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "plt.title(\"Validation Curve with MNB\")\n",
    "plt.xlabel(r\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid()\n",
    "lw = 2\n",
    "\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw,subsx='all')\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw,subsx='all')\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn; seaborn.set()  # plot formatting\n",
    "\n",
    "X_test = train_use_tf2_s\n",
    "y_test = tweets_train.target\n",
    "plt.scatter(train_use_tf2_s[\"sentiment_score\"], y_test, color='black')\n",
    "axis = plt.axis()\n",
    "for degree in [1, 3, 5]:\n",
    "    y_test = PolynomialRegression(degree).fit(X, y_test).predict(X_test)\n",
    "    plt.plot(X_test.ravel(), y_test, label='degree={0}'.format(degree))\n",
    "plt.xlim(-0.1, 1.0)\n",
    "plt.ylim(-2, 12)\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Busqueda de hiperparametros\n",
    "Busco los mejores hiperparametros para los distintos modelos probando diferentes vectorizaciones (siempre que sea posible)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para hacer validacion cruzada. Recibe dos parametros: El modelo a analizar (classifier) y los parametros a probar. Devuelve los mejores parametros de la validacion cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convierto la lista a dataframe, le agrego las columnas de KEYWORD\n",
    "train_use_tf2 = pd.DataFrame(train_use_tf)\n",
    "train_use_k_tf2 = pd.DataFrame(train_use_tf_k)\n",
    "train_use_tf2_k = pd.concat([train_use_tf2, train_use_k_tf2], axis=1, sort=False)\n",
    "\n",
    "#Mismo pero con sentimient analysis\n",
    "train_use_tf2_s = pd.concat([train_use_tf2_k, train_df2['sentiment_score']], axis=1, sort=False)\n",
    "\n",
    "\n",
    "#---test----\n",
    "##Convierto la lista a dataframe, le agrego las columnas de KEYWORD\n",
    "test_use_tf2 = pd.DataFrame(test_use_tf)\n",
    "test_use_k_tf2 = pd.DataFrame(test_use_tf_k)\n",
    "test_use_tf2_k = pd.concat([test_use_tf2, test_use_k_tf2], axis=1, sort=False)\n",
    "\n",
    "#Mismo pero con sentimient analysis\n",
    "test_use_tf2_s = pd.concat([test_use_tf2_k, test_df2['sentiment_score']], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrego columnas a countvector y los demas???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diccionario con las vectorizaciones obtenidas previamente\n",
    "vectorDict = {    \n",
    "    \"Count Vector\": train_cv,\n",
    "    \"TF-IDF\": train_tf,\n",
    "    \"Count Vector + ng\": train_ng_cv,\n",
    "    \"TF-IDF + ng\": train_ng_tf,\n",
    "    \"Feature Hashing\": train_fh,\n",
    "    \"Word2Vec\": train_w2vec,\n",
    "    \"Word2Vec + TF-IDF\": train_w2vecTfid,\n",
    "    \"Universal sentence encoder\": train_use_tf2,\n",
    "    \"Universal full\":train_use_tf2_k,\n",
    "    \"USE Sentiment\" : train_use_tf2_s\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_validation(classifier,paramDict):\n",
    "    for key,param_grid in paramDict.items():\n",
    "        try:\n",
    "            grid_search = GridSearchCV(estimator= classifier[key], param_grid = param_grid, cv=3 , n_jobs = -1, verbose = 2)\n",
    "            grid_search.fit(vectorDict[key],tweets_train.target)\n",
    "            print(key)\n",
    "            print(grid_search.best_score_)\n",
    "            print(grid_search.best_params_)\n",
    "            print(grid_search.best_estimator_)\n",
    "        except Exception as e:\n",
    "            #agrego esto para los casos de vectores negativos para seguir adelante y no analizar ese modelo\n",
    "            print(e)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Gradient Boost\n",
    "Boosting is a sequential technique which works on the principle of ensemble. It combines a set of weak learners and delivers improved prediction accuracy. At any instant t, the model outcomes are weighed based on the outcomes of previous instant t-1. The outcomes predicted correctly are given a lower weight and the ones miss-classified are weighted higher. This technique is followed for a classification problem while a similar technique is used for regression.\n",
    "\n",
    "As discussed earlier, there are two types of parameter to be tuned here – tree based and boosting parameters. There are no optimum values for learning rate as low values always work better, given that we train on sufficient number of trees.\n",
    "\n",
    "Though, GBM is robust enough to not overfit with increasing trees, but a high number for a particular learning rate can lead to overfitting. But as we reduce the learning rate and increase trees, the computation becomes expensive and would take a long time to run on standard personal computers.\n",
    "\n",
    "Keeping all this in mind, we can take the following approach:\n",
    "\n",
    "1. Choose a relatively high learning rate. Generally the default value of 0.1 works but somewhere between 0.05 to 0.2 should work for different problems\n",
    "2. Determine the optimum number of trees for this learning rate. This should range around 40-70. Remember to choose a value on which your system can work fairly fast. This is because it will be used for testing various scenarios and determining the tree parameters.\n",
    "3. Tune tree-specific parameters for decided learning rate and number of trees. Note that we can choose different parameters to define a tree and I’ll take up an example here.\n",
    "4. Lower the learning rate and increase the estimators proportionally to get more robust models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning tree-specific parameters\n",
    "\n",
    "Now lets move onto tuning the tree parameters. I plan to do this in following stages:\n",
    "\n",
    "1. Tune max_depth and num_samples_split\n",
    "2. Tune min_samples_leaf\n",
    "3. Tune max_features\n",
    "\n",
    "The order of tuning variables should be decided carefully. You should take the variables with a higher impact on outcome first. For instance, max_depth and min_samples_split have a significant impact and we’re tuning those first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo Inicial\n",
    "modelGB = {\n",
    "    \"Universal sentence encoder\":GradientBoostingClassifier(learning_rate=0.1, n_estimators=60, subsample=0.8, random_state=2020),\n",
    "    \"Universal full\":GradientBoostingClassifier(learning_rate=0.1, n_estimators=60, subsample=0.8, random_state=2020)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_1 ={\n",
    "    \"Universal sentence encoder\":{'max_depth':range(2,10,2), 'min_samples_split':range(100,500,100)},\n",
    "    \"Universal full\":{'max_depth':range(2,10,2), 'min_samples_split':range(100,500,100)},\n",
    "}\n",
    "Cross_validation(modelGB,step_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#afinando los parametros (1)\n",
    "step_1_deep ={\n",
    "    \"Universal sentence encoder\":{'max_depth':[4], 'min_samples_split':[200]},\n",
    "    \"Universal full\":{'max_depth':[2], 'min_samples_split':[150,170,190]}\n",
    "}\n",
    "Cross_validation(modelGB,step_1_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo PASO 2\n",
    "modelGB = {\n",
    "    \"Universal sentence encoder\":GradientBoostingClassifier(learning_rate=0.1, n_estimators=60, subsample=0.8, random_state=2020,max_depth=4,min_samples_split=200),\n",
    "    \"Universal full\":GradientBoostingClassifier(learning_rate=0.1, n_estimators=60, subsample=0.8, random_state=2020,max_depth=2,min_samples_split=190,max_features=38)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_2 = {\n",
    "    \"Universal sentence encoder\":{'min_samples_split':range(20,170,25), 'min_samples_leaf':range(30,50,5)},\n",
    "    \"Universal full\":{'min_samples_split':range(20,180,10), 'min_samples_leaf':range(30,50,5)}\n",
    "}\n",
    "Cross_validation(modelGB,step_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_2_deep = {\n",
    "    \"Universal sentence encoder\":{'min_samples_split':[100,110,125], 'min_samples_leaf':[39,40,41]},\n",
    "    \"Universal full\":{'min_samples_split':[5,10,15], 'min_samples_leaf':[29,30,31]}\n",
    "}\n",
    "Cross_validation(modelGB,step_2_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo PASO 3\n",
    "modelGB = {\n",
    "    \"Universal sentence encoder\":GradientBoostingClassifier(max_depth=4, min_samples_leaf=41,\n",
    "                           min_samples_split=125, n_estimators=60,\n",
    "                           random_state=2020, subsample=0.8),\n",
    "    \"Universal full\":GradientBoostingClassifier(max_depth=2, max_features=38, min_samples_leaf=30,\n",
    "                           min_samples_split=5, n_estimators=60,\n",
    "                           random_state=2020, subsample=0.8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_3 = {\n",
    "    \"Universal sentence encoder\":{'max_features':range(19,22,1),'min_samples_split':[105,110,115], 'min_samples_leaf':[39,41,42,44]},\n",
    "    \"Universal full\":{\"max_features\":range(37,39,1),'min_samples_split':[1,2,3,4,5], 'min_samples_leaf':[30]}\n",
    "}\n",
    "Cross_validation(modelGB,step_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo PASO 4\n",
    "modelGB = {\n",
    "    \"Universal sentence encoder\":GradientBoostingClassifier(max_depth=4, max_features=19, min_samples_leaf=42,\n",
    "                           min_samples_split=110, n_estimators=60,\n",
    "                           random_state=2020, subsample=0.8),\n",
    "    \"Universal full\":GradientBoostingClassifier(max_depth=2, max_features=38, min_samples_leaf=30,\n",
    "                           n_estimators=60, random_state=2020, subsample=0.8)  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_4 = {\n",
    "    \"Universal sentence encoder\":{'subsample':[0.75,0.77,0.8,0.83,0.85]},\n",
    "    \"Universal full\":{'subsample':[0.75,0.77,0.8,0.83,0.85]}\n",
    "}\n",
    "Cross_validation(modelGB,step_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo PASO 5\n",
    "modelGB = {\n",
    "    \"Universal sentence encoder\":GradientBoostingClassifier(max_depth=4, max_features=19, min_samples_leaf=42,\n",
    "                           min_samples_split=110, n_estimators=60,\n",
    "                           random_state=2020, subsample=0.8),\n",
    "    \"Universal full\":GradientBoostingClassifier(max_depth=2, max_features=38, min_samples_leaf=30,\n",
    "                           n_estimators=60, random_state=2020, subsample=0.8)  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_5 = {\n",
    "    \"Universal sentence encoder\":{'n_estimators':range(100,10000,500),'learning_rate':[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]},\n",
    "    \"Universal full\":{'n_estimators':range(100,10000,500),'learning_rate':[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]}\n",
    "}\n",
    "Cross_validation(modelGB,step_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRA, ANALISIS DE SENTIMIENTOS:\n",
    "Agrego pasos para probar modelo con analisis de sentimiento...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Dataframe con analisis de sentimiento:\n",
    "train_use_tf2_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo Inicial\n",
    "modelGB = {\n",
    "    \"USE Sentiment\":GradientBoostingClassifier(learning_rate=0.1, n_estimators=60, subsample=0.8, random_state=2020),\n",
    "}\n",
    "step_1 ={\n",
    "    \"USE Sentiment\":{'max_depth':range(2,10,2), 'min_samples_split':range(100,500,100)}\n",
    "}\n",
    "Cross_validation(modelGB,step_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_1 ={\n",
    "    \"USE Sentiment\":{'max_depth':[2], 'min_samples_split':[10,30,50,60,70]}\n",
    "}\n",
    "Cross_validation(modelGB,step_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 2\n",
    "modelGB = {\n",
    "    \"USE Sentiment\":GradientBoostingClassifier(max_depth=2, min_samples_split=10, n_estimators=60,\n",
    "                           random_state=2020, subsample=0.8)\n",
    "}\n",
    "step_2 = {\n",
    "    \"USE Sentiment\":{'min_samples_split':range(1,20,2), 'min_samples_leaf':range(30,50,5)}\n",
    "}\n",
    "Cross_validation(modelGB,step_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 2- ajuste\n",
    "modelGB = {\n",
    "    \"USE Sentiment\":GradientBoostingClassifier(max_depth=2, min_samples_split=10, n_estimators=60,\n",
    "                           random_state=2020, subsample=0.8)\n",
    "}\n",
    "step_2 = {\n",
    "    \"USE Sentiment\":{'min_samples_split':range(1,4,1), 'min_samples_leaf':range(26,34,1)}\n",
    "}\n",
    "Cross_validation(modelGB,step_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 3\n",
    "modelGB = {\n",
    "    \"USE Sentiment\":GradientBoostingClassifier(max_depth=2, min_samples_leaf=31, n_estimators=60,\n",
    "                           random_state=2020, subsample=0.8)\n",
    "}\n",
    "step_3 = {\n",
    "    \"USE Sentiment\":{'max_features':range(23,28,1),'min_samples_split':[1,2,3,4,5,6], 'min_samples_leaf':range(1,30,1)},\n",
    "}\n",
    "Cross_validation(modelGB,step_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 4\n",
    "modelGB = {\n",
    "    \"USE Sentiment\":GradientBoostingClassifier(max_depth=2, max_features=27, min_samples_leaf=23,\n",
    "                           n_estimators=60, random_state=2020, subsample=0.8)\n",
    "}\n",
    "step_4 = {\n",
    "    \"USE Sentiment\":{'subsample':[0.785,0.79,0.795,0.8]}\n",
    "}\n",
    "Cross_validation(modelGB,step_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 5\n",
    "step_5 = {\n",
    "    \"USE Sentiment\":{'n_estimators':range(5000,10001,1000),'learning_rate':[0.0001,0.0005,0.001,0.005,0.01]}\n",
    "}\n",
    "Cross_validation(modelGB,step_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 5 - ajuste\n",
    "step_5 = {\n",
    "    \"USE Sentiment\":{'n_estimators':range(4840,4860,5),'learning_rate':[0.0052,0.0053,0.0054,0.0055,0.0057]}\n",
    "}\n",
    "Cross_validation(modelGB,step_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Logistic Regression\n",
    "pendiente explicar de que trata..\n",
    "Voy a usar USE de tf tambien aca....\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo Inicial\n",
    "modelLR = {\n",
    "    \"USE Sentiment\":LogisticRegression(),\n",
    "    \"Count Vector\": LogisticRegression(),\n",
    "    \"TF-IDF\": LogisticRegression(),\n",
    "    \"Count Vector + ng\": LogisticRegression(),\n",
    "    \"TF-IDF + ng\":LogisticRegression(),\n",
    "    \"Feature Hashing\":LogisticRegression(),\n",
    "    \"Word2Vec\": LogisticRegression(),\n",
    "    \"Word2Vec + TF-IDF\":LogisticRegression()\n",
    "}\n",
    "step_1 ={\n",
    "    \"USE Sentiment\":{'penalty':['l1', 'l2'], 'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                    'class_weight':[{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
    "                    'solver' : ['liblinear', 'saga']},\n",
    "    \"Count Vector\":{'penalty':['l1', 'l2'], 'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                    'class_weight':[{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
    "                    'solver' : ['liblinear', 'saga']},\n",
    "    \"TF-IDF\":{'penalty':['l1', 'l2'], 'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                    'class_weight':[{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
    "                    'solver' : ['liblinear', 'saga']},\n",
    "    \"Count Vector + ng\":{'penalty':['l1', 'l2'], 'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                    'class_weight':[{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
    "                    'solver' : ['liblinear', 'saga']},\n",
    "    \"TF-IDF + ng\":{'penalty':['l1', 'l2'], 'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                    'class_weight':[{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
    "                    'solver' : ['liblinear', 'saga']},\n",
    "    \"Feature Hashing\":{'penalty':['l1', 'l2'], 'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                    'class_weight':[{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
    "                    'solver' : ['liblinear', 'saga']},\n",
    "    \"Word2Vec\":{'penalty':['l1', 'l2'], 'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                    'class_weight':[{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
    "                    'solver' : ['liblinear', 'saga']},\n",
    "    \"Word2Vec + TF-IDF\":{'penalty':['l1', 'l2'], 'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                    'class_weight':[{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
    "                    'solver' : ['liblinear', 'saga']}\n",
    "}\n",
    "Cross_validation(modelLR,step_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo Paso 2 - Ajuste en C\n",
    "modelLR = {\n",
    "    \"USE Sentiment\":LogisticRegression(C=1, class_weight={0: 0.6, 1: 0.4}, solver='liblinear'),\n",
    "}\n",
    "step_2 ={\n",
    "    \"USE Sentiment\":{'C':[0.985,0.986,0.987,0.988,0.989,0.9899]}\n",
    "}\n",
    "Cross_validation(modelLR,step_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo Paso 3 \n",
    "modelLR = {\n",
    "    \"USE Sentiment\":LogisticRegression(C=0.985, class_weight={0: 0.6, 1: 0.4}, solver='liblinear'),\n",
    "}\n",
    "step_3 ={\n",
    "    \"USE Sentiment\":{'tol':[0.0001,0.0002,0.0005,0.001,0.002,0.005]}\n",
    "}\n",
    "Cross_validation(modelLR,step_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import decomposition\n",
    "sc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "logistic = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import decomposition\n",
    "sc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "#Agrego pipeline para mejorar la entrada del logistic Reg.\n",
    "pipe = Pipeline(steps=[('sc', sc),\n",
    "                           ('pca', pca),\n",
    "                           ('logistic', logistic)])\n",
    "    \n",
    "# Create Parameter Space\n",
    "# Create a list of a sequence of integers from 1 to 30 (the number of features in X + 1)\n",
    "n_components = list(range(1,train_use_tf2_s.shape[1]+1,100))\n",
    "# Create a list of values of the regularization parameter\n",
    "C = [0.985,0.986,0.987,0.988,0.989,0.9899]\n",
    "# Create a list of options for the regularization penalty\n",
    "penalty = ['l1', 'l2']\n",
    "# Create a dictionary of all the parameter options \n",
    "# Note has you can access the parameters of steps of a pipeline by using '__’\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                  logistic__C=C,\n",
    "                  logistic__penalty=penalty)    \n",
    "\n",
    "modelLR = {\n",
    "    \"USE Sentiment\":pipe,\n",
    "}\n",
    "step_1 ={\n",
    "    \"USE Sentiment\":parameters\n",
    "}\n",
    "\n",
    "Cross_validation(modelLR,step_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Organizo algoritmos\n",
    "Para tener un poco mas ordenado todo, agrupo los algortimos en una colección para luego poder evaluarlos en bloque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo diccionario con los modelos de regresion a probar.\n",
    "modelsDict = {    \n",
    "    \"Gradient Boost\": GradientBoostingClassifier(n_estimators=10),\n",
    "    \"Random Forest\": RandomForestClassifier(max_depth = 10),  \n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth = 10),\n",
    "    \"kNN\": KNeighborsClassifier(n_neighbors=20),\n",
    "    'MNB': MultinomialNB(),\n",
    "    'GNB': GaussianNB(),\n",
    "    'RidgeClassifier': RidgeClassifier(class_weight='balanced'),\n",
    "    'Perceptron': Perceptron(class_weight='balanced'),\n",
    "    'xgboost': XGBClassifier(n_estimators=10),\n",
    "    \"Logistic Regression\": LogisticRegression(C=1.0)\n",
    "    }\n",
    "\n",
    "no_classifiers = len(modelsDict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_classify(x_train, y_train, x_test, y_test,positive_values = True):\n",
    "    df_results = pd.DataFrame(data=np.zeros(shape=(no_classifiers,6)), columns = ['Clasificador', 'Prec. train', 'Prec. test','AUC score','F1', 'Tiempo transcurrido'])\n",
    "    count = 0\n",
    "    for key, classifier in modelsDict.items():\n",
    "        if positive_values == False and key == \"MNB\":\n",
    "            continue\n",
    "            \n",
    "        t_start = process_time()  \n",
    "        try:\n",
    "            classifier.fit(x_train, y_train)\n",
    "            t_stop = process_time() \n",
    "            t_elapsed = t_stop - t_start        \n",
    "            y_predicted = classifier.predict(x_test)\n",
    "            df_results.loc[count,'AUC score'] = roc_auc_score(y_test, y_predicted)\n",
    "            df_results.loc[count,'Prec. train'] = round(classifier.score(x_train, y_train)*100)\n",
    "            df_results.loc[count,'Prec. test'] =round(accuracy_score(y_test,y_predicted)*100) \n",
    "            df_results.loc[count,'F1'] = f1_score(y_test, y_predicted, zero_division=1)\n",
    "        except Exception as e:\n",
    "            #agrego esto para los casos de vectores negativos para seguir adelante y no analizar ese modelo\n",
    "            print(e)\n",
    "        \n",
    "        df_results.loc[count,'Clasificador'] = key        \n",
    "        df_results.loc[count,'Tiempo transcurrido'] = t_elapsed                  \n",
    "        count+=1\n",
    "\n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Datos para countVector\n",
    "x_train_cv, x_test_cv, y_train_cv, y_test_cv =train_test_split(train_cv,tweets_train.target,test_size=0.2,random_state=2020)\n",
    "cv_results = batch_classify(x_train_cv, y_train_cv,x_test_cv, y_test_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos para TF-IDF\n",
    "x_train_tf, x_test_tf, y_train_tf, y_test_tf = train_test_split(train_tf,tweets_train.target,test_size=0.2,random_state=2020)\n",
    "tf_results = batch_classify(x_train_tf, y_train_tf,x_test_tf, y_test_tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos para countVector + n-gramas\n",
    "x_train_ng_cv, x_test_ng_cv, y_train_ng_cv, y_test_ng_cv =train_test_split(train_ng_cv,tweets_train.target,test_size=0.2,random_state=2020)\n",
    "cv_ng_results = batch_classify(x_train_ng_cv, y_train_ng_cv,x_test_ng_cv, y_test_ng_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos para TF-IDF + n-gramas\n",
    "x_train_ng_tf, x_test_ng_tf, y_train_ng_tf, y_test_ng_tf = train_test_split(train_ng_tf,tweets_train.target,test_size=0.2,random_state=2020)\n",
    "tf_ng_results = batch_classify(x_train_ng_tf, y_train_ng_tf,x_test_ng_tf, y_test_ng_tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos para Feature hashing\n",
    "x_train_fh, x_test_fh, y_train_fh, y_test_fh = train_test_split(train_fh,tweets_train.target,test_size=0.2,random_state=2020)\n",
    "fh_results = batch_classify(x_train_fh,y_train_fh,x_test_fh,y_test_fh,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos para w2vec\n",
    "x_train_w2vec, x_test_w2vec, y_train_w2vec, y_test_w2vec = train_test_split(train_w2vec,tweets_train.target,test_size=0.2,random_state=2020)\n",
    "w2vec_results = batch_classify(x_train_w2vec, y_train_w2vec,x_test_w2vec, y_test_w2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos para w2vec+tfid\n",
    "x_train_w2vecTfid, x_test_w2vecTfid, y_train_w2vecTfid, y_test_w2vecTfid = train_test_split(train_w2vecTfid,tweets_train.target,test_size=0.2,random_state=2020)\n",
    "w2vecTfid_results = batch_classify(x_train_w2vecTfid, y_train_w2vecTfid,x_test_w2vecTfid, y_test_w2vecTfid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos para U.S.E TF\n",
    "x_train_usetf, x_test_usetf, y_train_usetf, y_test_usetf = train_test_split(train_use_tf,tweets_train.target,test_size=0.2,random_state=2020)\n",
    "usetf_results = batch_classify(x_train_usetf, y_train_usetf,x_test_usetf, y_test_usetf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Resultados\n",
    "Comparo la performance de los distintos modelos probados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimo resultados para countVector\n",
    "cv_results.sort_values(by=[\"Prec. test\", \"AUC score\"], ascending=(False,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimo resultados para TF-IDF\n",
    "tf_results.sort_values(by=[\"Prec. test\", \"AUC score\"], ascending=(False,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimo resultados para countVector + n-gramas\n",
    "cv_ng_results.sort_values(by=[\"Prec. test\", \"AUC score\"], ascending=(False,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimo resultados para TF-IDF + n-gramas\n",
    "tf_ng_results.sort_values(by=[\"Prec. test\", \"AUC score\"], ascending=(False,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimo datos para Feature Hashing\n",
    "fh_results.sort_values(by=[\"Prec. test\",\"AUC score\"],ascending=(False,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2vec\n",
    "w2vec_results.sort_values(by=[\"Prec. test\", \"AUC score\"], ascending=(False,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2vec + tfid\n",
    "w2vecTfid_results.sort_values(by=[\"Prec. test\", \"AUC score\"], ascending=(False,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow universal setence encoder\n",
    "usetf_results.sort_values(by=[\"Prec. test\",\"AUC score\"],ascending=(False,False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Analísis general\n",
    "comparo las metricas de todos los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_classifier(x_train, y_train,title):\n",
    "    results = []\n",
    "    names = []\n",
    "    for key, classifier in modelsDict.items():\n",
    "        kfold = model_selection.KFold(n_splits=10, random_state=2020)\n",
    "        cv_results = model_selection.cross_val_score(classifier, x_train, y_train, cv=kfold, scoring='accuracy')\n",
    "        results.append(cv_results)\n",
    "        names.append(key)    \n",
    "        \n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    plt.title(title)\n",
    "    fig.suptitle('Comparación de algoritmos')    \n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot(results)\n",
    "    ax.set_xticklabels(names)    \n",
    "    plt.axhline(y=0.80, color='g', linestyle='-')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos para countVector\n",
    "graph_classifier(x_train_cv, y_train_cv,\"CountVector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos para TF-IDF\n",
    "graph_classifier(x_train_tf, y_train_tf,\"TF-IDF (1-2-grama)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos para countVector + n-gramas\n",
    "graph_classifier(x_train_ng_cv, y_train_ng_cv,\"CountVector (1-3-grama)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos para TF-IDF ngramas\n",
    "graph_classifier(x_train_ng_tf, y_train_ng_tf,\"TF-IDF (1-3-grama)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos para Feature Hashing\n",
    "graph_classifier(x_train_fh, y_train_fh,\"Feature Hashing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos para w2vec\n",
    "graph_classifier(x_train_w2vec, y_train_w2vec,\"w2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos para w2vec+tfid\n",
    "graph_classifier(x_train_w2vecTfid, y_train_w2vecTfid,\"w2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos para Tensorflor universal setence encode\n",
    "graph_classifier(x_train_usetf, y_train_usetf,\"Tensorflow USE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Mejora y selección de modelos\n",
    "Para encontrar las mejores configuraciones de los modelos, testeo distintos hiperparámetros dentro de cada modelo. Hago una selección entre los mejores candidatos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 Pre-seleccion de los mejores modelos\n",
    "Para no comparar todos los modelos y sus combinaciones, elijo los que mejor resultado dieron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del modelsDict[\"Key\"] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Búsqueda de hiperparámetros\n",
    "Veo los hiperparámetros que tiene cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, classifier in modelsDict.items():\n",
    "    print(\"Key: \" + key)\n",
    "    print(classifier.get_params().keys())\n",
    "    print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un diccionario para almacenar la colección de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsHyper = dict()\n",
    "modelsDict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.1 Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsHyper[\"Gradient Boost\"] = {\n",
    "    \"\":\"\",\n",
    "    \"\":\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsHyper[\"Random Forest\"] = {\n",
    "    \"\":\"\",\n",
    "    \"\":\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.3 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsHyper[\"Decision tree\"] = {\n",
    "    \"\":\"\",\n",
    "    \"\":\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.4 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsHyper[\"kNN\"] = {\n",
    "    \"\":\"\",\n",
    "    \"\":\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.5 MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsHyper[\"MNB\"] = {\n",
    "    \"\":\"\",\n",
    "    \"\":\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.6 GNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsHyper[\"GNB\"] = {\n",
    "    \"\":\"\",\n",
    "    \"\":\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.7 RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsHyper[\"Ridge Classifier\"] = {\n",
    "    \"\":\"\",\n",
    "    \"\":\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.8 Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsHyper[\"Perceptron\"] = {\n",
    "    \"\":\"\",\n",
    "    \"\":\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.9 xgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsHyper[\"xgboost\"] = {\n",
    "    \"\":\"\",\n",
    "    \"\":\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.10 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsHyper[\"Logistic Regression\"] = {\n",
    "    \"\":\"\",\n",
    "    \"\":\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Seleccion de Hiperparametros\n",
    "Utilizo gridsearch para buscar los mejores hiperparametros para cada modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_validation(classifier,param_grid):\n",
    "    grid_search = GridSearchCV(estimator= classifier, param_grid = param_grid, cv=3 , n_jobs = -1, verbose = 2)\n",
    "    grid_search.fit(x_train_usetf,y_train_usetf)\n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Envío de datos\n",
    "Preparo el submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(model,test_vector):\n",
    "    \n",
    "    '''Input- model=final fit model to be used for predictions\n",
    "              test_vector=pre-processed and vectorized test dataset\n",
    "       Output- submission file in .csv format with predictions       \n",
    "    \n",
    "    '''    \n",
    "    sub_df = pd.read_csv('../data/sample_submission.csv')\n",
    "    sub_df[\"target\"] = model.predict(test_vector)\n",
    "    sub_df.to_csv(\"submission.csv\", index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNB + countVector\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(x_train_cv, y_train_cv)\n",
    "submission(mnb_model,test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression +TF-IDF (1-2-gramas)\n",
    "lr_model = LogisticRegression(C=1.0)\n",
    "lr_model.fit(x_train_tf, y_train_tf)\n",
    "submission(lr_model,test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNB + TF-IDF (1-2-gramas)\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(x_train_tf, y_train_tf)\n",
    "submission(mnb_model,test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow + RandomForest (0.80324)\n",
    "trf_model = modelsDict[\"Random Forest\"]\n",
    "trf_model.fit(x_train_usetf,y_train_usetf)\n",
    "submission(trf_model,test_use_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow + Knn (0.78884)\n",
    "tknn_model = modelsDict[\"kNN\"]\n",
    "tknn_model.fit(x_train_usetf,y_train_usetf)\n",
    "submission(tknn_model,test_use_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow + Ridge (0.79221)\n",
    "trid_model = modelsDict[\"RidgeClassifier\"]\n",
    "trid_model.fit(x_train_usetf,y_train_usetf)\n",
    "submission(trid_model,test_use_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow + Logistic Reg (0.80416)\n",
    "tlr_model = modelsDict[\"Logistic Regression\"]\n",
    "tlr_model.fit(x_train_usetf,y_train_usetf)\n",
    "submission(tlr_model,test_use_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomforest + Hiperparams\n",
    "hip_model = modelsDict[\"RandomForest up\"]\n",
    "hip_model.fit(x_train_usetf,y_train_usetf)\n",
    "submission(hip_model,test_use_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflor --- logistic + Hyper (0.80876)\n",
    "lrh_model = LogisticRegression(C=0.615848211066026, solver='liblinear')\n",
    "lrh_model.fit(x_train_usetf,y_train_usetf)\n",
    "submission(lrh_model,test_use_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_use_tf2 = pd.DataFrame(train_use_tf)\n",
    "train_use_k_tf2 = pd.DataFrame(train_use_tf_k)\n",
    "train_use_tf2_k = pd.concat([train_use_tf2, train_use_k_tf2], axis=1, sort=False)\n",
    "\n",
    "test_use_tf2 = pd.DataFrame(test_use_tf)\n",
    "test_use_k_tf2 = pd.DataFrame(test_use_tf_k)\n",
    "test_use_tf2_full = pd.concat([test_use_tf2, test_use_k_tf2], axis=1, sort=False)\n",
    "\n",
    "x_train_usetf2, x_test_usetf2, y_train_usetf2, y_test_usetf2 = train_test_split(train_use_tf2_k,tweets_train.target,test_size=0.2,random_state=2020)\n",
    "\n",
    "#Tensorflow --- Gradient boost (0.81366)\n",
    "tgb_model = GradientBoostingClassifier(learning_rate=0.001, max_depth=2, max_features=38,\n",
    "                           min_samples_leaf=30, n_estimators=9600,\n",
    "                           random_state=2020, subsample=0.8)\n",
    "tgb_model.fit(x_train_usetf2,y_train_usetf2)\n",
    "submission(tgb_model,test_use_tf2_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_usetf, x_test_usetf, y_train_usetf, y_test_usetf = train_test_split(train_use_tf,tweets_train.target,test_size=0.2,random_state=2020)\n",
    "\n",
    "#Tensorflow --- gradient boost hyper SOLO TEXT (0.80508)\n",
    "gb_model = GradientBoostingClassifier(max_depth=4, max_features=19, min_samples_leaf=42,\n",
    "                           min_samples_split=110, n_estimators=60,\n",
    "                           random_state=2020, subsample=0.8)\n",
    "gb_model.fit(x_train_usetf,y_train_usetf)\n",
    "submission(gb_model,test_use_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TENSORFLOW --- gradient boost Hyper TEXT + KEYWORD + SENTIMENT (0.82010)\n",
    "\n",
    "train_use_tf2 = pd.DataFrame(train_use_tf)\n",
    "train_use_k_tf2 = pd.DataFrame(train_use_tf_k)\n",
    "train_use_tf2_k = pd.concat([train_use_tf2, train_use_k_tf2], axis=1, sort=False)\n",
    "train_use_tf2_s = pd.concat([train_use_tf2_k, train_df2['sentiment_score']], axis=1, sort=False)\n",
    "\n",
    "test_use_tf2 = pd.DataFrame(test_use_tf)\n",
    "test_use_k_tf2 = pd.DataFrame(test_use_tf_k)\n",
    "test_use_tf2_full = pd.concat([test_use_tf2, test_use_k_tf2], axis=1, sort=False)\n",
    "test_use_tf2_s = pd.concat([test_use_tf2_full, test_df2['sentiment_score']], axis=1, sort=False)\n",
    "\n",
    "x_train_usetf_sen, x_test_usetf_sen, y_train_usetf_sen, y_test_usetf_sen = train_test_split(train_use_tf2_s,tweets_train.target,test_size=0.2,random_state=2020)\n",
    "\n",
    "sen_model = GradientBoostingClassifier(learning_rate=0.0055, max_depth=2, max_features=27,\n",
    "                           min_samples_leaf=23, n_estimators=4850,\n",
    "                           random_state=2020, subsample=0.8)\n",
    "sen_model.fit(x_train_usetf_sen, y_train_usetf_sen)\n",
    "submission(sen_model,test_use_tf2_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow --- gradient boost hyper + text + key + sent + Ajustes extra\n",
    "sen_model2 = GradientBoostingClassifier(learning_rate=0.0053, max_depth=2, max_features=27,\n",
    "                           min_samples_leaf=23, n_estimators=4840,\n",
    "                           random_state=2020, subsample=0.8)\n",
    "sen_model2.fit(x_train_usetf_sen,y_train_usetf_sen)\n",
    "submission(sen_model,test_use_tf2_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow + Logistic regression (full) (0.81428)\n",
    "log_model = LogisticRegression(C=0.985, class_weight={0: 0.6, 1: 0.4}, solver='liblinear',tol=0.0001)\n",
    "log_model.fit(x_train_usetf_sen,y_train_usetf_sen)\n",
    "submission(log_model,test_use_tf2_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow + Logistic regression (full) + PIPELINE (0.81213)\n",
    "log_model = Pipeline(steps=[('pca', PCA(n_components=1025)),\n",
    "                \n",
    "                           ('boost', sen_model)])\n",
    "log_model.fit(x_train_usetf_sen,y_train_usetf_sen)\n",
    "submission(log_model,test_use_tf2_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_model = Pipeline(steps=[('sc',StandardScaler()),('pca',PCA(n_components=100)),\n",
    "                           ('boost', sen_model)])\n",
    "sen_model.fit(x_train_usetf_sen,y_train_usetf_sen)\n",
    "submission(sen_model,test_use_tf2_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
