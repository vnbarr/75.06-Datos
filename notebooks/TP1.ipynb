{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 1: Enunciado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El trabajo práctico 1 de la materia se basa en el análisis de los tweets del set de datos de la competencia: https://www.kaggle.com/c/nlp-getting-started.  \n",
    "\n",
    "- id - identificador unico para cada  tweet\n",
    "- text - el texto del tweet\n",
    "- location - ubicación desde donde fue enviado (podría no estar)\n",
    "- keyword - un keyword para el tweet  (podría faltar)\n",
    "- target - en train.csv, indica si se trata de un desastre real  (1) o no (0)\n",
    "\n",
    "El objetivo del primer TP es realizar un análisis exploratorio del set de datos. Queremos ver qué cosas podemos descubrir sobre los datos que puedan resultar interesantes. Estas cosas pueden estar relacionadas al objetivo del TP2 (predecir si un cierto tweet es real o no) o no, ambas son de interés.\n",
    "\n",
    "Los requisitos de la primera entrega son los siguientes:\n",
    "\n",
    "- El análisis debe estar hecho en Python Pandas o R.\n",
    "- El análisis debe entregarse en formato pdf vía gradescope. En el informe no va código.\n",
    "- Informar el link a un repositorio Github en donde pueda bajarse el código completo para generar el análisis.\n",
    "\n",
    "La evaluación del TP se realizará en base al siguiente criterio:\n",
    "\n",
    "- Originalidad del análisis exploratorio. \n",
    "- Calidad del reporte. ¿Está bien escrito? ¿Es claro y preciso? \n",
    "- Calidad del análisis exploratorio: qué tipo de preguntas se hacen y de qué forma se responden, ¿es la respuesta clara y concisa con respecto a la pregunta formulada? \n",
    "- Calidad de las visualizaciones presentadas.\n",
    "  - ¿Tienen todos los ejes su rótulo?\n",
    "  - ¿Tiene cada visualización un título?\n",
    "  - ¿Es entendible la visualización sin tener que leer la explicación?\n",
    "  - ¿El tipo de plot elegido es adecuado para lo que se quiere visualizar?\n",
    "  - ¿Es una visualización interesante?\n",
    "  - ¿El uso del color es adecuado?\n",
    "  - ¿Hay un exceso o falta de elementos visuales en la visualización elegida?\n",
    "  - ¿La visualización es consistente con los datos?\n",
    "- Conclusiones presentadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalación de librerías a usar\n",
    "# para escapear html\n",
    "!pip install bs4\n",
    "# para normalización del texto\n",
    "!pip install nltk\n",
    "!pip install stopwords\n",
    "# visualización nube de palabras\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importacion general de librerias y de visualizacion (matplotlib y seaborn)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "from html import unescape\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('default') # haciendo los graficos un poco mas bonitos en matplotlib\n",
    "#plt.rcParams['figure.figsize'] = (20, 10)\n",
    "\n",
    "sns.set(style=\"whitegrid\") # seteando tipo de grid en seaborn\n",
    "\n",
    "pd.options.display.float_format = '{:20,.2f}'.format # suprimimos la notacion cientifica en los outputs\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('../data/train.csv', encoding='utf-8')\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregado de nuevas columnas y limpieza del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primera normalización del texto, pasamos a lowercase \n",
    "tweets['normalized_text'] = tweets.text.str.lower()\n",
    "# solo para facilitar algunas visualizaciones\n",
    "tweets['target_name']= np.where(tweets['target']==1 ,'SI','NO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización del texto y nuevas columnas a partir del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminamos los links del texto normalizado y guardamos los links en una columna a parte por si sirven a futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPATTERN = r'(https?://\\S+)' \n",
    "\n",
    "tweets['urls'] = tweets.normalized_text.apply(lambda x: re.findall(URLPATTERN, x))\n",
    "tweets['normalized_text'] = tweets.normalized_text.apply(lambda x: re.sub(URLPATTERN,\"\", x))\n",
    "# cuento la cantidad de links en los tweets\n",
    "tweets['url_count'] = tweets.urls.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminamos los hashtags del texto normalizado y lo dejamos en otra columna junto con el count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuento la cantidad de hashtags en los tweets\n",
    "# nueva columna con el total de hashtags, y los hashtags\n",
    "tweets['hashtags'] = tweets.normalized_text.apply(lambda x: re.findall(r\"#(\\w+)\", x))\n",
    "tweets['hashtags_count'] = tweets.hashtags.str.len()\n",
    "tweets['normalized_text'] = tweets.normalized_text.apply(lambda x: re.sub(r\"#(\\w+)\",\"\", x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminamos los tags del texto y lo dejamos en otra columna junto con el count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuento la cantidad de ags en los tweets\n",
    "# nueva columna con el total de tags, y los tags\n",
    "tweets['tags'] = tweets.text.str.lower().apply(lambda x: re.findall(r\"@(\\w+)\", x))\n",
    "tweets['normalized_text'] = tweets.normalized_text.apply(lambda x: re.sub(r\"@(\\w+)\",\"\", x))\n",
    "tweets['tags_count'] = tweets.tags.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contamos cantidad de oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['sentences_count'] = tweets.normalized_text.apply(lambda x : len(sent_tokenize(x))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminamos signos de puntuación y html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = str.maketrans('', '', string.punctuation) \n",
    "# !\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~\n",
    "\n",
    "def remove_punctuation(text):        \n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_htmlsymbols(text):\n",
    "    soup = BeautifulSoup(unescape(text))\n",
    "    return soup.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emoji patterns\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)\n",
    "\n",
    "def remove_emojis_non_ascii(text):    \n",
    "    #replace consecutive non-ASCII characters with a space\n",
    "    result = re.sub(r'[^\\x00-\\x7F]+',' ', text)\n",
    "    #remove emojis from tweet\n",
    "    result = emoji_pattern.sub(r'', result)    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['normalized_text'] = tweets.normalized_text.apply(remove_htmlsymbols)\n",
    "tweets['normalized_text'] = tweets.normalized_text.apply(remove_punctuation)\n",
    "tweets['normalized_text'] = tweets.normalized_text.apply(remove_emojis_non_ascii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminamos stop words y creamos nueva columna con array de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertimos el texto en listado de palabras y despues borramos las stop words\n",
    "tweets['words'] = tweets.normalized_text.str.split()\n",
    "stop_words = stopwords.words('english')\n",
    "tweets['normalized_words'] = tweets['words'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "# eliminar las stop words del texto normalizado\n",
    "tweets['normalized_text'] = [' '.join(map(str, l)) for l in tweets['normalized_words']]\n",
    "# vemos como queda el dataset\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analizamos si el texto tiene números y guardamos el dato en una nueva columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esto chequea números como 1,2 y tambíen escrito como one, two\n",
    "def existence_of_numeric_data(text):\n",
    "    text=nltk.word_tokenize(text)\n",
    "    pos = nltk.pos_tag(text)\n",
    "    count = 0\n",
    "    for i in range(len(pos)):\n",
    "        word , pos_tag = pos[i]\n",
    "        if pos_tag == 'CD':\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con 1 si tiene , 0 sino\n",
    "tweets['has_numbers'] = tweets.normalized_text.apply(existence_of_numeric_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización de la columna keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos \"%20\" que representa espacio\n",
    "tweets['keywords'] = tweets.keyword.str.replace('%20',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correccion tipo de datos en keyword/location para optimizacion de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['keyword', 'location']:\n",
    "    tweets[col] = tweets[col].astype('category')\n",
    "#check de tipos de datos categoricos \n",
    "tweets.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregado de columna para indicar si tiene o no location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true si tiene location, false si no\n",
    "tweets['has_location'] = ~tweets['location'].isna()\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregado de columnas para Análisis de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a float for sentiment strength based on the input text. Positive values are positive valence, negative value are negative valence.\n",
    "tweets['sentiment_score'] = tweets.normalized_text.apply(lambda x: sid.polarity_scores(x))\n",
    "tweets['sentiment_score_compound'] = tweets.sentiment_score.apply(lambda x: x['compound'])\n",
    "tweets['sentiment_score_pos'] = tweets.sentiment_score.apply(lambda x: x['pos'])\n",
    "tweets['sentiment_score_neg'] = tweets.sentiment_score.apply(lambda x: x['neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vemos cómo queda el dataset\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"target_name\", y=\"url_count\", data=tweets, palette=\"cubehelix\")\n",
    "ax = sns.stripplot(x=\"target_name\", y=\"url_count\", data=tweets) #scatterplot\n",
    "ax.set_title(\"Cantidad de links por tweet y su veracidad\", fontsize=18)\n",
    "ax.set_xlabel(\"Real?\", fontsize=14)\n",
    "ax.set_ylabel(\"# links\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of 2 variables\n",
    "p1=sns.kdeplot(tweets[tweets['target'] == 0]['url_count'], shade=True, color=\"r\")\n",
    "p1=sns.kdeplot(tweets[tweets['target'] == 1]['url_count'], shade=True, color=\"b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=\"target_name\", y=\"url_count\", data=tweets, palette=\"cubehelix\")\n",
    "ax.set_title(\"Cantidad de links por tweet y su veracidad\", fontsize=18)\n",
    "ax.set_xlabel(\"Real?\", fontsize=14)\n",
    "ax.set_ylabel(\"# links\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Números en el texto del tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['has_numbers_name']= np.where(tweets['has_numbers']==1 ,'SI','NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tweets_numbers = sns.countplot(data=tweets,x=\"target_name\", hue=\"has_numbers_name\", palette=\"cubehelix\")\n",
    "plot_tweets_numbers.set_title(\"Cantidad de tweets que contienen números y su veracidad\", fontsize=18)\n",
    "plot_tweets_numbers.set_xlabel(\"Real?\", fontsize=14)\n",
    "plot_tweets_numbers.set_ylabel(\"Cantidad de tweets\", fontsize=14)\n",
    "plot_tweets_numbers.legend(loc='upper left', title='Tweets con números?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"target_name\", y=\"hashtags_count\", data=tweets, palette=\"cubehelix\")\n",
    "ax = sns.stripplot(x=\"target_name\", y=\"hashtags_count\", data=tweets) #scatterplot\n",
    "ax.set_title(\"Cantidad de hashtags por tweet y su veracidad\", fontsize=18)\n",
    "ax.set_xlabel(\"Real?\", fontsize=14)\n",
    "ax.set_ylabel(\"# hashtags\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hashtags_count = sns.countplot(x='hashtags_count',data=tweets,hue='target_name', palette=\"cubehelix\")\n",
    "plot_hashtags_count.set_title(\"Cantidad de tweets que contienen hashtags y su veracidad\", fontsize=18)\n",
    "plot_hashtags_count.set_xlabel(\"Cantidad de hashtags\", fontsize=14)\n",
    "plot_hashtags_count.set_ylabel(\"Cantidad de tweets\", fontsize=14)\n",
    "plot_hashtags_count.legend(loc='upper right', title='Tweets verderos?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"target_name\", y=\"tags_count\", data=tweets, palette=\"cubehelix\")\n",
    "ax = sns.stripplot(x=\"target_name\", y=\"tags_count\", data=tweets) #scatterplot\n",
    "ax.set_title(\"Cantidad de tags por tweet y su veracidad\", fontsize=18)\n",
    "ax.set_xlabel(\"Real?\", fontsize=14)\n",
    "ax.set_ylabel(\"# tags\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de oraciones en el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"target_name\", y=\"sentences_count\", data=tweets, palette=\"cubehelix\")\n",
    "ax = sns.stripplot(x=\"target_name\", y=\"sentences_count\", data=tweets) #scatterplot\n",
    "ax.set_title(\"Cantidad de oraciones por tweet y su veracidad\", fontsize=18)\n",
    "ax.set_xlabel(\"Real?\", fontsize=14)\n",
    "ax.set_ylabel(\"# oraciones\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sentences_count = sns.countplot(x='sentences_count',data=tweets,hue='target_name', palette=\"cubehelix\")\n",
    "plot_sentences_count.set_title(\"Cantidad de oraciones por tweet y su veracidad\", fontsize=18)\n",
    "plot_sentences_count.set_xlabel(\"Cantidad de oraciones\", fontsize=14)\n",
    "plot_sentences_count.set_ylabel(\"Cantidad de tweets\", fontsize=14)\n",
    "plot_sentences_count.legend(loc='upper right', title='Tweets verderos?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de los keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupo por keyword y cuento la cantidad de apariciones que tienen y el promedio del target para sacar una suerte de \"probabilidad de catastrofe\"\n",
    "probability = tweets.groupby('keywords').agg({'target':'mean'}).rename(columns={'target':'Probabilidad de Catastrofe'})\n",
    "probability.sort_values('Probabilidad de Catastrofe', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability.sort_values('Probabilidad de Catastrofe', ascending=False).head(50).plot(kind='bar',figsize=(16,8),rot=85,title='Probabilidad de catástrofe según keyword')\n",
    "ax=plt.gca()\n",
    "ax.set_ylabel('Probabilidad');\n",
    "ax.set_xlabel('Keyword')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de sentimientos en el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_fakes = tweets[tweets.target == 0]['sentiment_score_compound']\n",
    "sentiment_valid = tweets[tweets.target == 1]['sentiment_score_compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot( sentiment_valid , color=\"skyblue\", label=\"Valids\",hist=False)\n",
    "ax = sns.distplot( sentiment_fakes , color=\"red\", label=\"Fakes\",hist=False)\n",
    "plt.legend()\n",
    "ax.set_title(\"Distribución de los sentimientos de los tweets según veracidad\")\n",
    "ax.set_xlabel(\"Score Sentimiento compound\", fontsize=14)\n",
    "ax.set_ylabel(\"Frecuencia\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# los válidos tienen mas sentimientos negativos que positivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nube de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordcloud para textos fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me quedo con todos los textos fakes\n",
    "fakes = tweets[tweets.target == 0]\n",
    "fakes_text = \" \".join(review for review in fakes.normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and generate a word cloud image:\n",
    "wordcloud_fake = WordCloud(max_font_size=80, max_words=500, background_color=\"white\").generate(fakes_text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud_fake, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "wordcloud_fake.to_file(\"wordcloud_fake.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordcloud para textos reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me quedo con todos los textos reales\n",
    "reales= tweets[tweets.target == 1]\n",
    "reales_text = \" \".join(review for review in reales.normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and generate a word cloud image:\n",
    "wordcloud_real = WordCloud(max_font_size=80, max_words=500, background_color=\"white\").generate(reales_text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud_real, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "wordcloud_real.to_file(\"wordcloud_real.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {},
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
