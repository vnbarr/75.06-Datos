{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 1: Enunciado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El trabajo práctico 1 de la materia se basa en el análisis de los tweets del set de datos de la competencia: https://www.kaggle.com/c/nlp-getting-started.  \n",
    "\n",
    "- id - identificador unico para cada  tweet\n",
    "- text - el texto del tweet\n",
    "- location - ubicación desde donde fue enviado (podría no estar)\n",
    "- keyword - un keyword para el tweet  (podría faltar)\n",
    "- target - en train.csv, indica si se trata de un desastre real  (1) o no (0)\n",
    "\n",
    "El objetivo del primer TP es realizar un análisis exploratorio del set de datos. Queremos ver qué cosas podemos descubrir sobre los datos que puedan resultar interesantes. Estas cosas pueden estar relacionadas al objetivo del TP2 (predecir si un cierto tweet es real o no) o no, ambas son de interés.\n",
    "\n",
    "Los requisitos de la primera entrega son los siguientes:\n",
    "\n",
    "- El análisis debe estar hecho en Python Pandas o R.\n",
    "- El análisis debe entregarse en formato pdf vía gradescope. En el informe no va código.\n",
    "- Informar el link a un repositorio Github en donde pueda bajarse el código completo para generar el análisis.\n",
    "\n",
    "La evaluación del TP se realizará en base al siguiente criterio:\n",
    "\n",
    "- Originalidad del análisis exploratorio. \n",
    "- Calidad del reporte. ¿Está bien escrito? ¿Es claro y preciso? \n",
    "- Calidad del análisis exploratorio: qué tipo de preguntas se hacen y de qué forma se responden, ¿es la respuesta clara y concisa con respecto a la pregunta formulada? \n",
    "- Calidad de las visualizaciones presentadas.\n",
    "  - ¿Tienen todos los ejes su rótulo?\n",
    "  - ¿Tiene cada visualización un título?\n",
    "  - ¿Es entendible la visualización sin tener que leer la explicación?\n",
    "  - ¿El tipo de plot elegido es adecuado para lo que se quiere visualizar?\n",
    "  - ¿Es una visualización interesante?\n",
    "  - ¿El uso del color es adecuado?\n",
    "  - ¿Hay un exceso o falta de elementos visuales en la visualización elegida?\n",
    "  - ¿La visualización es consistente con los datos?\n",
    "- Conclusiones presentadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalación de librerías a usar\n",
    "# para escapear html\n",
    "!pip install bs4\n",
    "# para normalización del texto\n",
    "!pip install nltk\n",
    "!pip install stopwords\n",
    "# visualización nube de palabras\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importacion general de librerias y de visualizacion (matplotlib y seaborn)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "from html import unescape\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "#Para generar una paleta de colores equivalente a cubehelix(sns) en matplotlib\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('default') # haciendo los graficos un poco mas bonitos en matplotlib\n",
    "#plt.rcParams['figure.figsize'] = (20, 10)\n",
    "\n",
    "sns.set(style=\"whitegrid\") # seteando tipo de grid en seaborn\n",
    "\n",
    "pd.options.display.float_format = '{:20,.2f}'.format # suprimimos la notacion cientifica en los outputs\n",
    "\n",
    "#Nueva paleta de colores para matplotlib\n",
    "color_hex_arr = [\"#2B6F39\", \"#C2D8F2\",\"#182D48\",\"#A1784A\",\"#D38FC5\"]\n",
    "cubehelix_map = ListedColormap(sns.color_palette(color_hex_arr).as_hex())\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('../data/train.csv', encoding='utf-8')\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregado de nuevas columnas y limpieza del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primera normalización del texto, pasamos a lowercase \n",
    "tweets['normalized_text'] = tweets.text.str.lower()\n",
    "# solo para facilitar algunas visualizaciones\n",
    "tweets['target_name']= np.where(tweets['target']==1 ,'SI','NO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización del texto y nuevas columnas a partir del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminamos los links del texto normalizado y guardamos los links en una columna a parte por si sirven a futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPATTERN = r'(https?://\\S+)' \n",
    "\n",
    "tweets['urls'] = tweets.normalized_text.apply(lambda x: re.findall(URLPATTERN, x))\n",
    "tweets['normalized_text'] = tweets.normalized_text.apply(lambda x: re.sub(URLPATTERN,\"\", x))\n",
    "# cuento la cantidad de links en los tweets\n",
    "tweets['url_count'] = tweets.urls.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminamos los hashtags del texto normalizado y lo dejamos en otra columna junto con el count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuento la cantidad de hashtags en los tweets\n",
    "# nueva columna con el total de hashtags, y los hashtags\n",
    "tweets['hashtags'] = tweets.normalized_text.apply(lambda x: re.findall(r\"#(\\w+)\", x))\n",
    "tweets['hashtags_count'] = tweets.hashtags.str.len()\n",
    "tweets['normalized_text'] = tweets.normalized_text.apply(lambda x: re.sub(r\"#(\\w+)\",\"\", x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminamos los tags del texto y lo dejamos en otra columna junto con el count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuento la cantidad de ags en los tweets\n",
    "# nueva columna con el total de tags, y los tags\n",
    "tweets['tags'] = tweets.text.str.lower().apply(lambda x: re.findall(r\"@(\\w+)\", x))\n",
    "tweets['normalized_text'] = tweets.normalized_text.apply(lambda x: re.sub(r\"@(\\w+)\",\"\", x))\n",
    "tweets['tags_count'] = tweets.tags.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contamos cantidad de oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['sentences_count'] = tweets.normalized_text.apply(lambda x : len(sent_tokenize(x))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminamos signos de puntuación y html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = str.maketrans('', '', string.punctuation) \n",
    "# !\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~\n",
    "\n",
    "def remove_punctuation(text):        \n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_htmlsymbols(text):\n",
    "    soup = BeautifulSoup(unescape(text))\n",
    "    return soup.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emoji patterns\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)\n",
    "\n",
    "def remove_emojis_non_ascii(text):    \n",
    "    #replace consecutive non-ASCII characters with a space\n",
    "    result = re.sub(r'[^\\x00-\\x7F]+',' ', text)\n",
    "    #remove emojis from tweet\n",
    "    result = emoji_pattern.sub(r'', result)    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['normalized_text'] = tweets.normalized_text.apply(remove_htmlsymbols)\n",
    "tweets['normalized_text'] = tweets.normalized_text.apply(remove_punctuation)\n",
    "tweets['normalized_text'] = tweets.normalized_text.apply(remove_emojis_non_ascii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminamos stop words y creamos nueva columna con array de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertimos el texto en listado de palabras y despues borramos las stop words\n",
    "tweets['words'] = tweets.normalized_text.str.split()\n",
    "stop_words = stopwords.words('english')\n",
    "tweets['normalized_words'] = tweets['words'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "# eliminar las stop words del texto normalizado\n",
    "tweets['normalized_text'] = [' '.join(map(str, l)) for l in tweets['normalized_words']]\n",
    "# vemos como queda el dataset\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contador de palabras y frecuencia de aparición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contamos la cantidad de palabras de cada tweet\n",
    "tweets['words_counter'] = tweets.normalized_words.apply(Counter)\n",
    "# me quedo con las palabras que mas ocurrencias tienen en cada row\n",
    "tweets['word_max_appearance'] = tweets.words_counter.apply( lambda x: max(x) if x else None)  \n",
    "tweets['word_max_appearance_count'] =  tweets.words_counter.apply( lambda x: max(x.values()) if x else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analizamos si el texto tiene números y guardamos el dato en una nueva columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esto chequea números como 1,2 y tambíen escrito como one, two\n",
    "def existence_of_numeric_data(text):\n",
    "    text=nltk.word_tokenize(text)\n",
    "    pos = nltk.pos_tag(text)\n",
    "    count = 0\n",
    "    for i in range(len(pos)):\n",
    "        word , pos_tag = pos[i]\n",
    "        if pos_tag == 'CD':\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con 1 si tiene , 0 sino\n",
    "tweets['has_numbers'] = tweets.normalized_text.apply(existence_of_numeric_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpio la columna location de caracteres inválidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['location'] = tweets.location.str.replace('$','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización de la columna keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos \"%20\" que representa espacio\n",
    "tweets['keywords'] = tweets.keyword.str.replace('%20',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correccion tipo de datos en keyword/location para optimizacion de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['keyword', 'location']:\n",
    "    tweets[col] = tweets[col].astype('category')\n",
    "#check de tipos de datos categoricos \n",
    "tweets.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregado de columna para indicar si tiene o no location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true si tiene location, false si no\n",
    "tweets['has_location'] = ~tweets['location'].isna()\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregado de columnas para Análisis de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a float for sentiment strength based on the input text. Positive values are positive valence, negative value are negative valence.\n",
    "tweets['sentiment_score'] = tweets.normalized_text.apply(lambda x: sid.polarity_scores(x))\n",
    "tweets['sentiment_score_compound'] = tweets.sentiment_score.apply(lambda x: x['compound'])\n",
    "tweets['sentiment_score_pos'] = tweets.sentiment_score.apply(lambda x: x['pos'])\n",
    "tweets['sentiment_score_neg'] = tweets.sentiment_score.apply(lambda x: x['neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vemos cómo queda el dataset\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quito NaNs de columna Location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'None' not in tweets['location'].value_counts():\n",
    "    tweets['location'] = tweets['location'].cat.add_categories(\"None\").fillna('None')\n",
    "    \n",
    "tweets['text_in_location'] = tweets[['text','location']].apply(lambda row: 'Existe' if row.location in row.text else 'No existe' ,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de tweets Reales y Falsos (Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweets_target = tweets[['id','target_name']].groupby('target_name').count().rename(columns={'id':'cantidad'})\n",
    "\n",
    "# Grafico barplot\n",
    "g = sns.barplot(x=\"target_name\", y=\"cantidad\", data=tweets_target.reset_index(),palette=\"cubehelix\",order=['SI','NO'])\n",
    "g.set_title(\"Cantidad de tweets reales y falsos\", fontsize=18)\n",
    "g.set_xlabel(\"¿Real?\", fontsize=14)\n",
    "g.set_ylabel(\"N° Tweets\", fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"target_name\", y=\"url_count\", data=tweets, palette=\"cubehelix\")\n",
    "ax = sns.stripplot(x=\"target_name\", y=\"url_count\", data=tweets) #scatterplot\n",
    "ax.set_title(\"Cantidad de links por tweet y su veracidad\", fontsize=18)\n",
    "ax.set_xlabel(\"¿Real?\", fontsize=14)\n",
    "ax.set_ylabel(\"# links\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El comportamiento parecería ser bastante similar en los tweets verdaderos que en los falsos con respecto a la cantidad de links que se utilizan, \n",
    "aunque se ven más anomalías en los tweets falsos. Para poder tener un mejor análisis realizamos a continuación un gráfico de densidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot( tweets[tweets['target'] == 1]['url_count'] , color=color_hex_arr[0], label=\"Tweets Verdaderos\",hist=False)\n",
    "ax = sns.distplot( tweets[tweets['target'] == 0]['url_count'] , color=color_hex_arr[4], label=\"Tweets Falsos\",hist=False)\n",
    "plt.legend()\n",
    "ax.set_title(\"Distribución de links en los tweets según veracidad\", fontsize=18)\n",
    "ax.set_xlabel(\"Cantidad de links\", fontsize=14)\n",
    "ax.set_ylabel(\"Frecuencia\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ver este gráfico podemos ver que los tweets que resultan falsos suelen tener menos links que los tweets verdaderos pero como ya vimos en el boxplot siguen habiendo anomalías donde tweets con 4 links resultan falsos esto lo terminamos de confirmar del todo en el siguiente plot de violin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=\"target_name\", y=\"url_count\", data=tweets, palette=\"cubehelix\")\n",
    "ax.set_title(\"Cantidad de links por tweet y su veracidad\", fontsize=18)\n",
    "ax.set_xlabel(\"¿Real?\", fontsize=14)\n",
    "ax.set_ylabel(\"# links\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bajo la hipótesis de que el post sobre una catástrofe puede ir acompañado por datos numéricos (cantidad de heridos por ejemplo) decidimos analizar este \n",
    "dato en el texto. Este gráfico nos muestra que en general ya sean reales o no, los tweets no suelen tener datos numéricos. Por lo cual no nos aporta mucha\n",
    "información para distinguir una categoría de la otra y descartamos este feature agregado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cantidad de hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hashtags_count = sns.countplot(x='hashtags_count',data=tweets,hue='target_name', palette=\"cubehelix\")\n",
    "plot_hashtags_count.set_title(\"Cantidad de tweets que contienen hashtags y su veracidad\", fontsize=18)\n",
    "plot_hashtags_count.set_xlabel(\"Cantidad de hashtags\", fontsize=14)\n",
    "plot_hashtags_count.set_ylabel(\"Cantidad de tweets\", fontsize=14)\n",
    "plot_hashtags_count.legend(loc='upper right', title='¿Tweet Real?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este gráfico podemos observar que en general los tweets no suelen usar demasiados hashtags y los que no usan ninguno son mayor % los falsos, por lo que \n",
    "en principio podemos ver que cuanto menos hashtags mejor para identificar un tweet falso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 hashtags por categoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_true = tweets[(tweets['target'] == 1) & (tweets['hashtags_count'] > 0)]['hashtags']\n",
    "hashtags_false = tweets[(tweets['target'] == 0) & (tweets['hashtags_count'] > 0)]['hashtags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_true_all = pd.value_counts(hashtags_true.apply(pd.Series).stack())\n",
    "hashtags_false_all = pd.value_counts(hashtags_false.apply(pd.Series).stack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,2,figsize=(10,6))\n",
    "sns.barplot(x=hashtags_true_all.head(10).values,y=hashtags_true_all.head(10).index,color=color_hex_arr[0],ax=ax[0],orient=\"h\").\\\n",
    "    set(title = 'Verdaderos',xlabel='N° tweets')\n",
    "sns.barplot(x=hashtags_false_all.head(10).values,y=hashtags_false_all.head(10).index,color=color_hex_arr[4],ax=ax[1],orient=\"h\").\\\n",
    "    set(title = 'Falsos',xlabel='N° tweets')\n",
    "fig.subplots_adjust(top=0.87,wspace = 0.5)\n",
    "fig.suptitle('Top 10 hashtags', fontsize=18)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los hashtags de news, best y hot se repiten en ambas categorías, predominando \"news\" en el set de datos verdaderos. El resto de los hashtags de tweets verdaderos (en su mayoría) tienen que ver con catastrófes mientras que los fakes no tienen nada que ver con esa temática (hay varios que hacen referencias a trabajos: jobs, job, hiring)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cantidad de tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot( tweets[tweets['target'] == 1]['tags_count'] , label=\"Tweets Verdaderos\",hist=False, color=color_hex_arr[0])\n",
    "ax = sns.distplot( tweets[tweets['target'] == 0]['tags_count'] , label=\"Tweets Falsos\",hist=False, color=color_hex_arr[4])\n",
    "plt.legend()\n",
    "ax.set_title(\"Distribución de cantidad de tags en los tweets según veracidad\", fontsize=18)\n",
    "ax.set_xlabel(\"Cantidad de tags\", fontsize=14)\n",
    "ax.set_ylabel(\"Frecuencia\", fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que al igual que en los hashtags, en general no se usan muchos tags pero sí se usan un poco más en los tweets falsos que en los verdaderos.\n",
    "Esto puede ser para conseguir más seguidores por ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 tags por categoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_true = tweets[(tweets['target'] == 1) & (tweets['tags_count'] > 0)]['tags']\n",
    "tags_false = tweets[(tweets['target'] == 0) & (tweets['tags_count'] > 0)]['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_true_all = pd.value_counts(tags_true.apply(pd.Series).stack())\n",
    "tags_false_all = pd.value_counts(tags_false.apply(pd.Series).stack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,2,figsize=(10,6))\n",
    "sns.barplot(x=tags_true_all.head(10).values,y=tags_true_all.head(10).index,color=color_hex_arr[0],ax=ax[0],orient=\"h\").\\\n",
    "    set(title = 'Verdaderos',xlabel='N° tweets')\n",
    "sns.barplot(x=tags_false_all.head(10).values,y=tags_false_all.head(10).index,color=color_hex_arr[4],ax=ax[1],orient=\"h\").\\\n",
    "    set(title = 'Falsos',xlabel='N° tweets')\n",
    "fig.subplots_adjust(top=0.87,wspace = 0.5)\n",
    "fig.suptitle('Top 10 tags', fontsize=18)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que con los hashtags, acá también algunos tags se repiten, como youtube, usatoday.\n",
    "En los tweets verderos tenemos tags que hacen referencia a entidades del gobierno (como usagov) y medios de comunicación (como fox news, usatoday, unsuckdcmetro) mientras que en los falsos se hace referencia a artistas conocidos entre otras cosas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de oraciones en el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sentences_count = sns.countplot(x='sentences_count',data=tweets,hue='target_name', palette=\"cubehelix\")\n",
    "plot_sentences_count.set_title(\"Cantidad de oraciones por tweet y su veracidad\", fontsize=18)\n",
    "plot_sentences_count.set_xlabel(\"Cantidad de oraciones\", fontsize=14)\n",
    "plot_sentences_count.set_ylabel(\"Cantidad de tweets\", fontsize=14)\n",
    "plot_sentences_count.legend(loc='upper right', title='¿Tweet Real?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este gráfico podemos observar que a medida que aumenta la cantidad de oraciones en los tweets hay mayor proporción de tweets verdaderos. Por lo cual podríamos \n",
    "decir que el \"correcto armado\" de una oración podría ser importante a la hora de analizar la veracidad del mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de cantidad de palabras y largo del texto\n",
    "Analizo la cantidad de palabras (token_len) y lo analizo en relacion del largo del tweet (text_len Creo que daria el mismo resultado contando las palabras de Words o Normalized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_simple = pd.DataFrame()\n",
    "\n",
    "text_simple['cantidad_palabras'] = tweets['text'].apply(lambda x: len([token for token in x.split()]))\n",
    "text_simple['largo_texto'] = tweets['text'].apply(lambda x: len(x))\n",
    "text_simple['estado'] = tweets['target_name']\n",
    "\n",
    "g = sns.FacetGrid(text_simple, col=\"estado\",height=5,hue='estado',palette='cubehelix')\n",
    "\n",
    "g = g.map(sns.distplot, \"largo_texto\").set(ylabel=\"densidad\")\n",
    "plt.subplots_adjust(top=0.85)\n",
    "g.fig.suptitle('Largo de texto y veracidad', fontsize=18)\n",
    "axes = g.axes.flatten()\n",
    "axes[0].set_title(\"Verdaderos\", fontsize=14)\n",
    "axes[1].set_title(\"Falsos\", fontsize=14)\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otro grafico para mostrar la veracidad a partir de la cantidad de palabras\n",
    "g = sns.FacetGrid(text_simple, col=\"estado\",height=5,hue='estado',palette='cubehelix')\n",
    "g = g.map(sns.distplot, \"cantidad_palabras\").set(ylabel=\"densidad\")\n",
    "plt.subplots_adjust(top=0.85)\n",
    "g.fig.suptitle('Cantidad de palabras y veracidad', fontsize=18)\n",
    "axes = g.axes.flatten()\n",
    "axes[0].set_title(\"Verdaderos\", fontsize=14)\n",
    "axes[1].set_title(\"Falsos\", fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Números en el texto del tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['has_numbers_name']= np.where(tweets['has_numbers']==1 ,'SI','NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tweets_numbers = sns.countplot(data=tweets,x=\"target_name\", hue=\"has_numbers_name\", palette=\"cubehelix\")\n",
    "plot_tweets_numbers.set_title(\"Relación entre tweets con datos numéricos y su veracidad\", fontsize=18)\n",
    "plot_tweets_numbers.set_xlabel(\"¿Tweet Real?\", fontsize=14)\n",
    "plot_tweets_numbers.set_ylabel(\"Cantidad de tweets\", fontsize=14)\n",
    "plot_tweets_numbers.legend(loc='upper left', title='¿Tweets con números?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de los keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keywords_null = (tweets['keyword'].isnull()).value_counts().iloc[::-1]\n",
    "keywords_null = keywords_null.to_frame()\n",
    "#Keywords nulas = True\n",
    "keywords_null.rename(columns={\"keyword\":\"keywods nulos\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_null = keywords_null.rename(columns={'keyword': 'Datos en keyword'}, index={True: 'Sin datos',False:'Con datos'})\n",
    "keywords_null = pd.pivot_table(keywords_null, values='Datos en keyword',columns=['Sin datos','Con datos'])\n",
    "g = keywords_null.plot.bar(rot = 0,cmap=cubehelix_map,use_index =True)\n",
    "g.set(title = 'Cantidad de keywords nulas ',ylabel='Cantidad tweets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupo por keyword y cuento la cantidad de apariciones que tienen y el promedio del target para sacar una suerte de \"probabilidad de catastrofe\"\n",
    "probability = tweets.groupby('keywords').agg({'target':'mean'}).rename(columns={'target':'Probabilidad de Catastrofe'})\n",
    "probability.sort_values('Probabilidad de Catastrofe', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability.sort_values('Probabilidad de Catastrofe', ascending=False).\\\n",
    "    head(30).\\\n",
    "    plot(kind='bar',figsize=(10,6),rot=85,cmap = cubehelix_map)\n",
    "ax=plt.gca()\n",
    "ax.set_title('Probabilidad de catástrofe según keyword', fontsize=18)\n",
    "ax.set_ylabel('Probabilidad', fontsize=14)\n",
    "ax.set_xlabel('Keyword', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este gráfico podemos observar cuales son las keywords que están más relacionadas a tweets verdaderos, por lo que palabras como debris (escombros), wreckage (destrucción), derailment (descarrilamiento), outbreak (brote, epidemia), oil spill (derrame de petróleo) y typhoon (tifón) tienen una gran probabilidad de estar siendo usadas en tweets que resultan ciertos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de los keywords relacionados con la veracidad del tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_false = tweets[tweets[\"target\"] == 0][\"keyword\"].value_counts()\n",
    "keyword_true  = tweets[tweets[\"target\"] == 1][\"keyword\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(x=keyword_true.head(30).values,y=keyword_true.head(30).index.str.replace('%20',' '),color = color_hex_arr[0],orient=\"h\").\\\n",
    "    set(title = 'Top 30 keywords (Tweets reales)',xlabel='Apariciones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g = sns.barplot(x=keyword_false.head(30).values,y=keyword_false.head(30).index.str.replace('%20',' '),color=color_hex_arr[4],orient=\"h\").\\\n",
    "    set(title = 'Top 30 keywords (Tweets falsos)',xlabel='Apariciones')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tendencia de los keywords a aparecer dentro de un tweet real/falso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comparewords = pd.concat([keyword_true,keyword_false], axis=1)\n",
    "comparewords.columns=['real','falso']\n",
    "comparewords.index = comparewords.index.str.replace('%20',' ')\n",
    "comparewords = comparewords.fillna(0)\n",
    "comparewords = comparewords.sort_values(by=['real'])\n",
    "comparewords_ct = pd.concat([comparewords.head(35),comparewords.tail(35)])\n",
    "\n",
    "comparewords_ct.plot.barh(rot=0,figsize=(9,15),cmap = cubehelix_map).set(title='Aparición de palabras por tipo de tweet',xlabel='Apariciones')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de sentimientos en el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_fakes = tweets[tweets.target == 0]['sentiment_score_compound']\n",
    "sentiment_valid = tweets[tweets.target == 1]['sentiment_score_compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot( sentiment_valid , color=color_hex_arr[0], label=\"Tweets Verdaderos\",hist=False)\n",
    "ax = sns.distplot( sentiment_fakes , color=color_hex_arr[4], label=\"tweets Falsos\",hist=False)\n",
    "plt.legend()\n",
    "ax.set_title(\"Distribución de los sentimientos de los tweets según veracidad\", fontsize=18)\n",
    "ax.set_xlabel(\"Score Sentimientos\", fontsize=14)\n",
    "ax.set_ylabel(\"Frecuencia\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# los válidos tienen mas sentimientos negativos que positivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizando el sentimiento detrás de los textos podemos ver que los tweets que resultan verdaderos suelen tener más sentimientos negativos que los que resultan falsos. Esto tiene sentido ya que si un tweet es verdadero es probable que exprese preocupación por la catástrofe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nube de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordcloud para textos fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me quedo con todos los textos fakes\n",
    "fakes = tweets[tweets.target == 0]\n",
    "fakes_text = \" \".join(review for review in fakes.normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and generate a word cloud image:\n",
    "wordcloud_fake = WordCloud(max_font_size=100, max_words=800, margin=5, background_color=\"white\").generate(fakes_text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud_fake, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la nube de palabras asociada a los tweets falsos podemos ver que las palabra más frecuentes no tienen relación con una catástrofe pero tampoco podemos sacar\n",
    "demasiadas conclusiones al respecto.\n",
    "Aparece la palabra love lo que también sigue confirmando la presencia de sentimientos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordcloud para textos reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me quedo con todos los textos reales\n",
    "reales= tweets[tweets.target == 1]\n",
    "reales_text = \" \".join(review for review in reales.normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and generate a word cloud image:\n",
    "wordcloud_real = WordCloud(max_font_size=100, max_words=800, margin=5, background_color=\"white\").generate(reales_text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud_real, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la nubre de palabras asociada a los tweets verdaderos podemos ver más presencia de palabras asociadas a catástrofes, ya que se mencionan feńomenos como storm,\n",
    "flood, fire, suicide, bomber, police. La palabra people, via (quizás porque muchos son repost desde alguna otra app/pagina) y time se repite en ambas nubes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relacion entre location y existencia en el texto. \n",
    "Busco la relación entre la location de un tweet y que esta exista en el texto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_location = tweets['text_in_location'].value_counts().iloc[::-1]\n",
    "count_location = count_location.to_frame()\n",
    "count_location.columns= ['Location en tweet']\n",
    "count_location = pd.pivot_table(count_location, values='Location en tweet',columns=['Existe','No existe'])\n",
    "\n",
    "g = count_location.plot.bar(rot = 0,cmap=cubehelix_map,use_index =True)\n",
    "g.set(title = 'Correspondencia de location y su existencia en el texto*',ylabel='Cantidad tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Por lo visto no tiene mucho sentido analizar si existe relacion entre la correspondencia de location y la veracidad del tweet por la gran diferencia que existe entre ambos. Es un dato irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis sobre la columna location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cantidad de locations nulas (none) vs locations con datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_none = (tweets['location']=='None').value_counts().iloc[::-1]\n",
    "locations_none = locations_none.to_frame()\n",
    "\n",
    "locations_none.rename(columns={'location': 'tweet con location'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "locations_none = locations_none.rename(columns={'location': 'Datos en location'}, index={True: 'Sin datos',False:'Con datos'})\n",
    "locations_none = pd.pivot_table(locations_none, values='Datos en location',columns=['Sin datos','Con datos'])\n",
    "g = locations_none.plot.bar(rot = 0,cmap=cubehelix_map,use_index =True)\n",
    "g.set(title = 'Cantidad de nulos en location ',ylabel='Cantidad tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cantidad de tweets por location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_bar_true = tweets[(tweets[\"target\"] == 0)&(tweets[\"location\"]!= 'None')]['location'].value_counts()\n",
    "location_bar_false = tweets[(tweets[\"target\"] == 1)&(tweets[\"location\"]!= 'None')]['location'].value_counts()\n",
    "\n",
    "fig, ax =plt.subplots(1,2,figsize=(10,6))\n",
    "sns.barplot(x=location_bar_true.head(30).values,y=location_bar_true.head(30).index.str.replace('%20',' '),color=color_hex_arr[0],ax=ax[0],orient=\"h\").\\\n",
    "    set(title = 'Verdaderos',xlabel='N° tweets')\n",
    "sns.barplot(x=location_bar_false.head(30).values,y=location_bar_false.head(30).index.str.replace('%20',' '),color=color_hex_arr[4],ax=ax[1],orient=\"h\").\\\n",
    "    set(title = 'Falsos',xlabel='N° tweets')\n",
    "fig.subplots_adjust(top=0.87,wspace = 0.5)\n",
    "fig.suptitle('Cantidad de tweets por location', fontsize=18)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {},
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
